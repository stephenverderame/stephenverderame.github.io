<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>projects on</title><link>https://stephenverderame.github.io/tags/projects/</link><description>Stephen Verderame's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 12 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://stephenverderame.github.io/tags/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>Z3-Powered Constraint Solving for Static Analysis</title><link>https://stephenverderame.github.io/blog/null2/</link><pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/null2/</guid><description>In a previous post, we discussed implementing an analysis to detect potential uses of null pointers. The workhorse of this analysis was an interval analysis that could (conservatively) determine all possible values an integer could take on. We used this information to prove whether or not an array access could be determined to always be in-bounds.
This worked, but it could not handle cases such as a dynamically sized buffer. Suppose we know that a buffer has $a$ elements.</description></item><item><title>Fuzzing Compilers With Genetic Programming</title><link>https://stephenverderame.github.io/blog/bear/</link><pubDate>Wed, 20 Dec 2023 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/bear/</guid><description>Ensuring good test coverage of a compiler is hard. That&amp;rsquo;s why I developed Bear, a compiler fuzzer that generates random test cases for compiler optimization passes. (Named as such because bears are fuzzy?) Bear uses genetic programming to evolve novel programs in the search space. Bear generates programs in a custom DSL (domain-specific language) known as Bare C before being lowered into the target IR.
The IR Bear currently targets is BRIL (Big Red Intermediate Language), which is the IR used in Cornell&amp;rsquo;s PhD level compilers course.</description></item><item><title>Scheduling LLVM Passes with the New Pass Manager</title><link>https://stephenverderame.github.io/blog/scheduling_llvm/</link><pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/scheduling_llvm/</guid><description>Figuring out how to run a pass with LLVM feels needlessly complicated. This short post will briefly lay out two different methods of doing so using the new Pass Manager.
Invoking via Clang One simple method of running a compiler pass is to directly invoke it via Clang as outlined in this blog post.
This method is fairly straightforward and super easy, we just need to:
Create a class that inherits from PassInfoMixin, as described here.</description></item><item><title>Not Now Null Pointers: LLVM Null Analysis</title><link>https://stephenverderame.github.io/blog/null-check/</link><pubDate>Sat, 07 Oct 2023 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/null-check/</guid><description>I&amp;rsquo;ve always been interested in being able to make guarantees about the correctness of a program without the high cost of doing something like a full-on verification in an automatic theorem prover such as Coq. Moreover, avoiding extra runtime costs would be extremely nice as well, especially for systems programming domains.
I recently began working on an LLVM pass which aims to guarantee the absence of loading and storing of null pointers.</description></item><item><title>Do Your Units Match? An Embedded DSL for Physical Quantities</title><link>https://stephenverderame.github.io/blog/unit-types/</link><pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/unit-types/</guid><description>Computations of physical values in programming languages can quickly get out of hand due to the complex units that the programmer has to keep track of. Good variable naming and comments can help, but nothing is stopping double run_time_sec from storing a time measured in milliseconds. Furthermore, different functions might use the same value, but measured in different units, requiring manual conversions. Overall, it&amp;rsquo;s just an unpleasant burden placed on the programmer and a cause of many errors.</description></item><item><title>Real-Time, Accurate Collision Detection</title><link>https://stephenverderame.github.io/blog/oort-collisions/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/oort-collisions/</guid><description>Accurate collision detection is a vital part of video games and simulation, and fast collision detection is paramount for real-time applications such as games. In high school, building such a fast and accurate collision engine eluded me. This post describes, conceptually, the algorithm I settled upon when developing Project Oort. I will assume a basic familiarity with the problem of collision detection, including bounding spheres and axis-aligned bounding boxes, simple data structures like trees, and the basics of concrete linear algebra including vectors, matrices, and linear transformations.</description></item><item><title>The Case of the Disappearing Shadow: Gradual Shadow Fading</title><link>https://stephenverderame.github.io/blog/oort-shadows/</link><pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate><guid>https://stephenverderame.github.io/blog/oort-shadows/</guid><description>When implementing the cloaking ability for Project Oort, I came upon a somewhat interesting problem: At what point during the gradual disappearing process should the object&amp;rsquo;s shadow disappear?
At first, I just had the object abruptly stop writing to the depth buffer at a certain transparency threshold. This would cause the shadow to simply cut out at an arbitrary point. I didn&amp;rsquo;t like the look of that and decided that I wanted the shadow to fade in and out gradually.</description></item></channel></rss>